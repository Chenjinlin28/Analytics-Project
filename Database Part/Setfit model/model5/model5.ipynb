{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setfit model 2\n",
    "\n",
    "Input: entity, sentence\n",
    "\n",
    "Sentence transformer: all-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from setfit import SetFitModel, Trainer, TrainingArguments, sample_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "df = pd.read_csv('/Users/jinlinchen/Documents/Study/HWR Berlin/Semester 2/Analytics Lab/Analytics Project/Database Part/manual_label - consolidated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence_original</th>\n",
       "      <th>label</th>\n",
       "      <th>class_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retailer</td>\n",
       "      <td>which gives the supplier 's profit as and the ...</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>background_information</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Proposition 1</td>\n",
       "      <td>which gives the supplier 's profit as and the ...</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>belongs_to_article</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Supply-Chain</td>\n",
       "      <td>which gives the supplier 's profit as and the ...</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>background_information</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petri net</td>\n",
       "      <td>which can be equivalently represented with a P...</td>\n",
       "      <td>which can be equivalently represented with a P...</td>\n",
       "      <td>which can be equivalently represented with a P...</td>\n",
       "      <td>background_information</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business processes</td>\n",
       "      <td>which are sent by business processes accounts ...</td>\n",
       "      <td>A simple example of a synthesis process for IA...</td>\n",
       "      <td>which are sent by business processes accounts ...</td>\n",
       "      <td>background_information</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               entity                                           sentence  \\\n",
       "0            retailer  which gives the supplier 's profit as and the ...   \n",
       "1       Proposition 1  which gives the supplier 's profit as and the ...   \n",
       "2        Supply-Chain  which gives the supplier 's profit as and the ...   \n",
       "3           Petri net  which can be equivalently represented with a P...   \n",
       "4  business processes  which are sent by business processes accounts ...   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  which gives the supplier's profit as and the r...   \n",
       "1  which gives the supplier's profit as and the r...   \n",
       "2  which gives the supplier's profit as and the r...   \n",
       "3  which can be equivalently represented with a P...   \n",
       "4  A simple example of a synthesis process for IA...   \n",
       "\n",
       "                                   sentence_original                   label  \\\n",
       "0  which gives the supplier's profit as and the r...  background_information   \n",
       "1  which gives the supplier's profit as and the r...      belongs_to_article   \n",
       "2  which gives the supplier's profit as and the r...  background_information   \n",
       "3  which can be equivalently represented with a P...  background_information   \n",
       "4  which are sent by business processes accounts ...  background_information   \n",
       "\n",
       "   class_ID  \n",
       "0         3  \n",
       "1         1  \n",
       "2         3  \n",
       "3         3  \n",
       "4         3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>sentence_original</th>\n",
       "      <th>class_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retailer</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Proposition 1</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Supply-Chain</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petri net</td>\n",
       "      <td>which can be equivalently represented with a P...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business processes</td>\n",
       "      <td>which are sent by business processes accounts ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               entity                                  sentence_original  \\\n",
       "0            retailer  which gives the supplier's profit as and the r...   \n",
       "1       Proposition 1  which gives the supplier's profit as and the r...   \n",
       "2        Supply-Chain  which gives the supplier's profit as and the r...   \n",
       "3           Petri net  which can be equivalently represented with a P...   \n",
       "4  business processes  which are sent by business processes accounts ...   \n",
       "\n",
       "   class_ID  \n",
       "0         3  \n",
       "1         1  \n",
       "2         3  \n",
       "3         3  \n",
       "4         3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract needed columns\n",
    "df = df[['entity', 'sentence_original', 'class_ID']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine entity and sentence into one text column\n",
    "df['text'] = df.apply(lambda row: f\"{row['entity']}, {row['sentence_original']}\", axis=1)\n",
    "\n",
    "# Rename 'class_ID' to 'label' to match SetFit expectations\n",
    "df = df.rename(columns={'class_ID': 'label'})\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the DataFrame to a Dataset object\n",
    "train_dataset = Dataset.from_pandas(train_df[['text', 'label']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>sentence_original</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>cybercrime</td>\n",
       "      <td>whereas the magnitude of the coefficient of fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>cybercrime, whereas the magnitude of the coeff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>framework</td>\n",
       "      <td>word2vec method is a self-supervised framework...</td>\n",
       "      <td>3</td>\n",
       "      <td>framework, word2vec method is a self-supervise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>organizational level</td>\n",
       "      <td>yuqing Ren, Sara kiesler, and Susan R. Fussell...</td>\n",
       "      <td>2</td>\n",
       "      <td>organizational level, yuqing Ren, Sara kiesler...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>online survey</td>\n",
       "      <td>zoomeRaNG GeNeRated a RaNdom set of 1,200 sale...</td>\n",
       "      <td>1</td>\n",
       "      <td>online survey, zoomeRaNG GeNeRated a RaNdom se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>evaluation of Internet</td>\n",
       "      <td>whose primary goal is to produce theory driven...</td>\n",
       "      <td>3</td>\n",
       "      <td>evaluation of Internet, whose primary goal is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>CFI was 0.924</td>\n",
       "      <td>x 2 /df was 3.67, which was below the acceptab...</td>\n",
       "      <td>1</td>\n",
       "      <td>CFI was 0.924, x 2 /df was 3.67, which was bel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>individual-level</td>\n",
       "      <td>whether the predictors display curvilinear eff...</td>\n",
       "      <td>2</td>\n",
       "      <td>individual-level, whether the predictors displ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>information technology</td>\n",
       "      <td>yet, as researchers, we do not often delve int...</td>\n",
       "      <td>3</td>\n",
       "      <td>information technology, yet, as researchers, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>British</td>\n",
       "      <td>with other international airlines such as Qant...</td>\n",
       "      <td>3</td>\n",
       "      <td>British, with other international airlines suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>unified modeling language</td>\n",
       "      <td>yet experts in the traditional mind-set seem t...</td>\n",
       "      <td>2</td>\n",
       "      <td>unified modeling language, yet experts in the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        entity  \\\n",
       "38                  cybercrime   \n",
       "143                  framework   \n",
       "84        organizational level   \n",
       "55               online survey   \n",
       "217     evaluation of Internet   \n",
       "..                         ...   \n",
       "106              CFI was 0.924   \n",
       "14            individual-level   \n",
       "92      information technology   \n",
       "179                    British   \n",
       "102  unified modeling language   \n",
       "\n",
       "                                     sentence_original  label  \\\n",
       "38   whereas the magnitude of the coefficient of fi...      1   \n",
       "143  word2vec method is a self-supervised framework...      3   \n",
       "84   yuqing Ren, Sara kiesler, and Susan R. Fussell...      2   \n",
       "55   zoomeRaNG GeNeRated a RaNdom set of 1,200 sale...      1   \n",
       "217  whose primary goal is to produce theory driven...      3   \n",
       "..                                                 ...    ...   \n",
       "106  x 2 /df was 3.67, which was below the acceptab...      1   \n",
       "14   whether the predictors display curvilinear eff...      2   \n",
       "92   yet, as researchers, we do not often delve int...      3   \n",
       "179  with other international airlines such as Qant...      3   \n",
       "102  yet experts in the traditional mind-set seem t...      2   \n",
       "\n",
       "                                                  text  \n",
       "38   cybercrime, whereas the magnitude of the coeff...  \n",
       "143  framework, word2vec method is a self-supervise...  \n",
       "84   organizational level, yuqing Ren, Sara kiesler...  \n",
       "55   online survey, zoomeRaNG GeNeRated a RaNdom se...  \n",
       "217  evaluation of Internet, whose primary goal is ...  \n",
       "..                                                 ...  \n",
       "106  CFI was 0.924, x 2 /df was 3.67, which was bel...  \n",
       "14   individual-level, whether the predictors displ...  \n",
       "92   information technology, yet, as researchers, w...  \n",
       "179  British, with other international airlines suc...  \n",
       "102  unified modeling language, yet experts in the ...  \n",
       "\n",
       "[202 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', '__index_level_0__'],\n",
       "    num_rows: 202\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', '__index_level_0__'],\n",
       "    num_rows: 51\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16864513a22e4008b309113f3a248149",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3098a67ef1eb4cef99d80779a93d38a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3d811329da4435a29110f7187a6740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ba12210b4342dcba83028b1fab86d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d21e7904ada44c4829ba21d40f47050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f10216ab51a43bbba49bf3861b7e02c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bd19cbaed84a62b9c1a16aba4c211f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfed2a77e3e4d6eb25f9ed6ff7316d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc45cddef0fe40e58b5b500eece494e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e62b6c1e57490d87fa14a2c8846f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fc538f6e5854048bd57e799a77a95e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from setfit import SetFitModel, Trainer, sample_dataset\n",
    "# Initialize the SetFit model\n",
    "model = SetFitModel.from_pretrained(\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SetFitModel(model_body=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 384, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_head=LogisticRegression(), multi_target_strategy=None, normalize_embeddings=False, labels=None, model_card_data=SetFitModelCardData(language=None, license=None, tags=['setfit', 'sentence-transformers', 'text-classification', 'generated_from_setfit_trainer'], model_name='SetFit with sentence-transformers/all-mpnet-base-v2', model_id=None, dataset_name=None, dataset_id=None, dataset_revision=None, task_name=None, st_id='sentence-transformers/all-mpnet-base-v2', hyperparameters={}, eval_results_dict={}, eval_lines_list=[], metric_lines=[], widget=[], predict_example=None, label_example_list=[], tokenizer_warning=False, train_set_metrics_list=[], train_set_sentences_per_label_list=[], code_carbon_callback=None, num_classes=None, best_model_step=None, metrics=['accuracy'], pipeline_tag='text-classification', library_name='setfit', version={'python': '3.11.6', 'setfit': '1.1.0.dev0', 'sentence_transformers': '3.0.0', 'transformers': '4.39.3', 'torch': '2.3.0', 'datasets': '2.19.2', 'tokenizers': '0.15.2'}))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No enough memory to run this, thus switching to cpu\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ld/mczz0xmx243grk32lg665c_c0000gn/T/ipykernel_65281/2917775467.py:10: DeprecationWarning: `SetFitTrainer` has been deprecated and will be removed in v2.0.0 of SetFit. Please use `Trainer` instead.\n",
      "  trainer = SetFitTrainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2be67daa6d34a6aa02acf5fa10846c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/202 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 8080\n",
      "  Batch size = 16\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 505\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fdb2b65889443580be9c0b265daa79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c32ff0988b464a7295c2bb854ef6ae63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.4085, 'learning_rate': 3.921568627450981e-07, 'epoch': 0.0}\n",
      "{'embedding_loss': 0.232, 'learning_rate': 1.9607843137254903e-05, 'epoch': 0.1}\n",
      "{'embedding_loss': 0.1501, 'learning_rate': 1.784140969162996e-05, 'epoch': 0.2}\n",
      "{'embedding_loss': 0.0558, 'learning_rate': 1.5638766519823788e-05, 'epoch': 0.3}\n",
      "{'embedding_loss': 0.0318, 'learning_rate': 1.3436123348017623e-05, 'epoch': 0.4}\n",
      "{'embedding_loss': 0.0133, 'learning_rate': 1.1233480176211456e-05, 'epoch': 0.5}\n",
      "{'embedding_loss': 0.001, 'learning_rate': 9.030837004405287e-06, 'epoch': 0.59}\n",
      "{'embedding_loss': 0.0009, 'learning_rate': 6.828193832599119e-06, 'epoch': 0.69}\n",
      "{'embedding_loss': 0.0016, 'learning_rate': 4.625550660792952e-06, 'epoch': 0.79}\n",
      "{'embedding_loss': 0.0008, 'learning_rate': 2.4229074889867843e-06, 'epoch': 0.89}\n",
      "{'embedding_loss': 0.0006, 'learning_rate': 2.2026431718061676e-07, 'epoch': 0.99}\n",
      "{'train_runtime': 5258.9633, 'train_samples_per_second': 1.536, 'train_steps_per_second': 0.096, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from setfit import SetFitTrainer\n",
    "import psutil\n",
    "\n",
    "\n",
    "\n",
    "# Create a Trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    loss_class=CosineSimilarityLoss\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained('/Users/jinlinchen/Documents/Study/HWR Berlin/Semester 2/Analytics Lab/Analytics Project/Database Part/Setfit model/model5/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'accuracy': 0.7058823529411765}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ld/mczz0xmx243grk32lg665c_c0000gn/T/ipykernel_65281/2239685966.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"f1\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/datasets/load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7058823529411765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.72      0.72        18\n",
      "           2       0.56      0.56      0.56         9\n",
      "           3       0.75      0.75      0.75        24\n",
      "\n",
      "    accuracy                           0.71        51\n",
      "   macro avg       0.68      0.68      0.68        51\n",
      "weighted avg       0.71      0.71      0.71        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from datasets import load_metric\n",
    "\n",
    "# Load the metric\n",
    "metric = load_metric(\"f1\")\n",
    "\n",
    "# Get predictions from the model\n",
    "preds = model(test_dataset[\"text\"])\n",
    "labels = test_dataset[\"label\"]\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score = metric.compute(predictions=preds, references=labels, average=\"weighted\")\n",
    "print(f\"F1 score: {f1_score['f1']}\")\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"1\", \"2\", \"3\"]  \n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(labels, preds, target_names=class_names)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
