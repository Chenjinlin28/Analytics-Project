{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "comet_ml is installed but `COMET_API_KEY` is not set.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from setfit import SetFitModel, Trainer, TrainingArguments, sample_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "df = pd.read_csv('/Users/jinlinchen/Documents/Study/HWR Berlin/Semester 2/Analytics Lab/Analytics Project/Database Part/manual_label - consolidated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>sentence</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>sentence_original</th>\n",
       "      <th>label</th>\n",
       "      <th>class_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retailer</td>\n",
       "      <td>which gives the supplier 's profit as and the ...</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>background_information</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Proposition 1</td>\n",
       "      <td>which gives the supplier 's profit as and the ...</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>belongs_to_article</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Supply-Chain</td>\n",
       "      <td>which gives the supplier 's profit as and the ...</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>background_information</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petri net</td>\n",
       "      <td>which can be equivalently represented with a P...</td>\n",
       "      <td>which can be equivalently represented with a P...</td>\n",
       "      <td>which can be equivalently represented with a P...</td>\n",
       "      <td>background_information</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business processes</td>\n",
       "      <td>which are sent by business processes accounts ...</td>\n",
       "      <td>A simple example of a synthesis process for IA...</td>\n",
       "      <td>which are sent by business processes accounts ...</td>\n",
       "      <td>background_information</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               entity                                           sentence  \\\n",
       "0            retailer  which gives the supplier 's profit as and the ...   \n",
       "1       Proposition 1  which gives the supplier 's profit as and the ...   \n",
       "2        Supply-Chain  which gives the supplier 's profit as and the ...   \n",
       "3           Petri net  which can be equivalently represented with a P...   \n",
       "4  business processes  which are sent by business processes accounts ...   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  which gives the supplier's profit as and the r...   \n",
       "1  which gives the supplier's profit as and the r...   \n",
       "2  which gives the supplier's profit as and the r...   \n",
       "3  which can be equivalently represented with a P...   \n",
       "4  A simple example of a synthesis process for IA...   \n",
       "\n",
       "                                   sentence_original                   label  \\\n",
       "0  which gives the supplier's profit as and the r...  background_information   \n",
       "1  which gives the supplier's profit as and the r...      belongs_to_article   \n",
       "2  which gives the supplier's profit as and the r...  background_information   \n",
       "3  which can be equivalently represented with a P...  background_information   \n",
       "4  which are sent by business processes accounts ...  background_information   \n",
       "\n",
       "   class_ID  \n",
       "0         3  \n",
       "1         1  \n",
       "2         3  \n",
       "3         3  \n",
       "4         3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>sentence_original</th>\n",
       "      <th>class_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>retailer</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Proposition 1</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Supply-Chain</td>\n",
       "      <td>which gives the supplier's profit as and the r...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Petri net</td>\n",
       "      <td>which can be equivalently represented with a P...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business processes</td>\n",
       "      <td>which are sent by business processes accounts ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               entity                                  sentence_original  \\\n",
       "0            retailer  which gives the supplier's profit as and the r...   \n",
       "1       Proposition 1  which gives the supplier's profit as and the r...   \n",
       "2        Supply-Chain  which gives the supplier's profit as and the r...   \n",
       "3           Petri net  which can be equivalently represented with a P...   \n",
       "4  business processes  which are sent by business processes accounts ...   \n",
       "\n",
       "   class_ID  \n",
       "0         3  \n",
       "1         1  \n",
       "2         3  \n",
       "3         3  \n",
       "4         3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract needed columns\n",
    "df = df[['entity', 'sentence_original', 'class_ID']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine entity and sentence into one text column\n",
    "df['text'] = df.apply(lambda row: f\"Entity: {row['entity']}, Sentence: {row['sentence_original']}\", axis=1)\n",
    "\n",
    "# Rename 'class_ID' to 'label' to match SetFit expectations\n",
    "df = df.rename(columns={'class_ID': 'label'})\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the DataFrame to a Dataset object\n",
    "train_dataset = Dataset.from_pandas(train_df[['text', 'label']])\n",
    "test_dataset = Dataset.from_pandas(test_df[['text', 'label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>sentence_original</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>cybercrime</td>\n",
       "      <td>whereas the magnitude of the coefficient of fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>Entity: cybercrime, Sentence: whereas the magn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>framework</td>\n",
       "      <td>word2vec method is a self-supervised framework...</td>\n",
       "      <td>3</td>\n",
       "      <td>Entity: framework, Sentence: word2vec method i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>organizational level</td>\n",
       "      <td>yuqing Ren, Sara kiesler, and Susan R. Fussell...</td>\n",
       "      <td>2</td>\n",
       "      <td>Entity: organizational level, Sentence: yuqing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>online survey</td>\n",
       "      <td>zoomeRaNG GeNeRated a RaNdom set of 1,200 sale...</td>\n",
       "      <td>1</td>\n",
       "      <td>Entity: online survey, Sentence: zoomeRaNG GeN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>evaluation of Internet</td>\n",
       "      <td>whose primary goal is to produce theory driven...</td>\n",
       "      <td>3</td>\n",
       "      <td>Entity: evaluation of Internet, Sentence: whos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>CFI was 0.924</td>\n",
       "      <td>x 2 /df was 3.67, which was below the acceptab...</td>\n",
       "      <td>1</td>\n",
       "      <td>Entity: CFI was 0.924, Sentence: x 2 /df was 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>individual-level</td>\n",
       "      <td>whether the predictors display curvilinear eff...</td>\n",
       "      <td>2</td>\n",
       "      <td>Entity: individual-level, Sentence: whether th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>information technology</td>\n",
       "      <td>yet, as researchers, we do not often delve int...</td>\n",
       "      <td>3</td>\n",
       "      <td>Entity: information technology, Sentence: yet,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>British</td>\n",
       "      <td>with other international airlines such as Qant...</td>\n",
       "      <td>3</td>\n",
       "      <td>Entity: British, Sentence: with other internat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>unified modeling language</td>\n",
       "      <td>yet experts in the traditional mind-set seem t...</td>\n",
       "      <td>2</td>\n",
       "      <td>Entity: unified modeling language, Sentence: y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>202 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        entity  \\\n",
       "38                  cybercrime   \n",
       "143                  framework   \n",
       "84        organizational level   \n",
       "55               online survey   \n",
       "217     evaluation of Internet   \n",
       "..                         ...   \n",
       "106              CFI was 0.924   \n",
       "14            individual-level   \n",
       "92      information technology   \n",
       "179                    British   \n",
       "102  unified modeling language   \n",
       "\n",
       "                                     sentence_original  label  \\\n",
       "38   whereas the magnitude of the coefficient of fi...      1   \n",
       "143  word2vec method is a self-supervised framework...      3   \n",
       "84   yuqing Ren, Sara kiesler, and Susan R. Fussell...      2   \n",
       "55   zoomeRaNG GeNeRated a RaNdom set of 1,200 sale...      1   \n",
       "217  whose primary goal is to produce theory driven...      3   \n",
       "..                                                 ...    ...   \n",
       "106  x 2 /df was 3.67, which was below the acceptab...      1   \n",
       "14   whether the predictors display curvilinear eff...      2   \n",
       "92   yet, as researchers, we do not often delve int...      3   \n",
       "179  with other international airlines such as Qant...      3   \n",
       "102  yet experts in the traditional mind-set seem t...      2   \n",
       "\n",
       "                                                  text  \n",
       "38   Entity: cybercrime, Sentence: whereas the magn...  \n",
       "143  Entity: framework, Sentence: word2vec method i...  \n",
       "84   Entity: organizational level, Sentence: yuqing...  \n",
       "55   Entity: online survey, Sentence: zoomeRaNG GeN...  \n",
       "217  Entity: evaluation of Internet, Sentence: whos...  \n",
       "..                                                 ...  \n",
       "106  Entity: CFI was 0.924, Sentence: x 2 /df was 3...  \n",
       "14   Entity: individual-level, Sentence: whether th...  \n",
       "92   Entity: information technology, Sentence: yet,...  \n",
       "179  Entity: British, Sentence: with other internat...  \n",
       "102  Entity: unified modeling language, Sentence: y...  \n",
       "\n",
       "[202 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', '__index_level_0__'],\n",
       "    num_rows: 202\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', '__index_level_0__'],\n",
       "    num_rows: 51\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from setfit import SetFitModel, Trainer, sample_dataset\n",
    "# Initialize the SetFit model\n",
    "model = SetFitModel.from_pretrained(\"sentence-transformers/paraphrase-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SetFitModel(model_body=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: MPNetModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "), model_head=LogisticRegression(), multi_target_strategy=None, normalize_embeddings=False, labels=None, model_card_data=SetFitModelCardData(language=None, license=None, tags=['setfit', 'sentence-transformers', 'text-classification', 'generated_from_setfit_trainer'], model_name='SetFit with sentence-transformers/paraphrase-mpnet-base-v2', model_id=None, dataset_name=None, dataset_id=None, dataset_revision=None, task_name=None, st_id='sentence-transformers/paraphrase-mpnet-base-v2', hyperparameters={}, eval_results_dict={}, eval_lines_list=[], metric_lines=[], widget=[], predict_example=None, label_example_list=[], tokenizer_warning=False, train_set_metrics_list=[], train_set_sentences_per_label_list=[], code_carbon_callback=None, num_classes=None, best_model_step=None, metrics=['accuracy'], pipeline_tag='text-classification', library_name='setfit', version={'python': '3.11.6', 'setfit': '1.1.0.dev0', 'sentence_transformers': '3.0.0', 'transformers': '4.39.3', 'torch': '2.3.0', 'datasets': '2.19.2', 'tokenizers': '0.15.2'}))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No enough memory to run this, thus switching to cpu\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ld/mczz0xmx243grk32lg665c_c0000gn/T/ipykernel_2506/2917775467.py:10: DeprecationWarning: `SetFitTrainer` has been deprecated and will be removed in v2.0.0 of SetFit. Please use `Trainer` instead.\n",
      "  trainer = SetFitTrainer(\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 202/202 [00:00<00:00, 19185.03 examples/s]\n",
      "***** Running training *****\n",
      "  Num unique pairs = 8080\n",
      "  Batch size = 16\n",
      "  Num epochs = 1\n",
      "  Total optimization steps = 505\n",
      "  0%|          | 0/505 [00:00<?, ?it/s]\n",
      "\n",
      "\u001b[A                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.3291, 'learning_rate': 3.921568627450981e-07, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                               "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2426, 'learning_rate': 1.9607843137254903e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.1409, 'learning_rate': 1.784140969162996e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0645, 'learning_rate': 1.5638766519823788e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.103, 'learning_rate': 1.3436123348017623e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0845, 'learning_rate': 1.1233480176211456e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0105, 'learning_rate': 9.030837004405287e-06, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0029, 'learning_rate': 6.828193832599119e-06, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0085, 'learning_rate': 4.625550660792952e-06, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.001, 'learning_rate': 2.4229074889867843e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0014, 'learning_rate': 2.2026431718061676e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 505/505 [1:28:20<00:00, 10.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 5301.1708, 'train_samples_per_second': 1.524, 'train_steps_per_second': 0.095, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from sentence_transformers.losses import CosineSimilarityLoss\n",
    "from setfit import SetFitTrainer\n",
    "import psutil\n",
    "\n",
    "\n",
    "\n",
    "# Create a Trainer\n",
    "trainer = SetFitTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    loss_class=CosineSimilarityLoss\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.save_pretrained('/Users/jinlinchen/Documents/Study/HWR Berlin/Semester 2/Analytics Lab/Analytics Project/Database part/model/model1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running evaluation *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'accuracy': 0.7058823529411765}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "results = trainer.evaluate()\n",
    "print(f\"Evaluation results: {results}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ld/mczz0xmx243grk32lg665c_c0000gn/T/ipykernel_2506/2239685966.py:5: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"f1\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/datasets/load.py:759: FutureWarning: The repository for f1 contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.19.2/metrics/f1/f1.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7047619047619048\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.59      0.89      0.71        18\n",
      "           2       0.83      0.56      0.67         9\n",
      "           3       0.83      0.62      0.71        24\n",
      "\n",
      "    accuracy                           0.71        51\n",
      "   macro avg       0.75      0.69      0.70        51\n",
      "weighted avg       0.75      0.71      0.70        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from datasets import load_metric\n",
    "\n",
    "# Load the metric\n",
    "metric = load_metric(\"f1\")\n",
    "\n",
    "# Get predictions from the model\n",
    "preds = model(test_dataset[\"text\"])\n",
    "labels = test_dataset[\"label\"]\n",
    "\n",
    "# Calculate F1 score\n",
    "f1_score = metric.compute(predictions=preds, references=labels, average=\"weighted\")\n",
    "print(f\"F1 score: {f1_score['f1']}\")\n",
    "\n",
    "# Define class names manually\n",
    "class_names = [\"1\", \"2\", \"3\"]  # Replace with your actual class names\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(labels, preds, target_names=class_names)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
